{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23e99752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:87: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if key[i] is '0':\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:96: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if key[measuring_qubit] is '0':\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:158: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:160: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"probabilities_per_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:162: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"measure_one_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:170: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:196: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:198: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"probabilities_per_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:206: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error =  'Invalid option devices'\n"
     ]
    }
   ],
   "source": [
    "from classes.QCircuits import *\n",
    "from classes.QnnTorchConnector import *\n",
    "from classes.CsvDataset import *\n",
    "from classes.Utils import *\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import RealAmplitudes, ZFeatureMap, ZZFeatureMap\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit.algorithms.optimizers import SPSA, SLSQP, L_BFGS_B, COBYLA\n",
    "\n",
    "import numpy as np\n",
    "from math import log\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch as T\n",
    "\n",
    "from sklearn import datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1a7e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0            1            2            3            4\n",
      "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
      "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
      "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
      "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
      "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
      "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
      "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
      "max       6.824800    12.951600    17.927400     2.449500     1.000000\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "T.manual_seed(seed)\n",
    "\n",
    "# BANKNOTE DATASET. \n",
    "# define the location of the dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/banknote_authentication.csv'\n",
    "n=2\n",
    "\n",
    "dataset_name = 'banknote'\n",
    "save_path = 'loss_data/'+dataset_name+'_'\n",
    "\n",
    "df = read_csv(url, header=None)\n",
    "print(df.describe())   \n",
    "epochs = 15\n",
    "\n",
    "\n",
    "dataset = CsvDataset(df=df, features=(0,2), target=4)\n",
    "\n",
    "train_dl, test_dl = create_train_test_dataloader(dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a0ef89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdoAAAFiCAYAAABRfRm3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAhC0lEQVR4nO3deZRU5Z3w8e9T3VXdTQPd7KKIBEVRVBTBCGoAjVtEZUCNUWdckkzGaDTm1cniFqIziTFmRp28r4mixmXUGEUwRgzBNUElCLiAyqaiQQSEBnqt6qrn/QNCQEXR+IDC93NOn3TXrbr1qzonfrm3bt0bYoxIkqQ0Mlt6AEmStmaGVpKkhAytJEkJGVpJkhIytJIkJWRoJUlKqDzFSjt37hx79eqVYtWSJH0qPfvss8tijF3efXuS0Pbq1Ytp06alWLUkSZ9KIYTX3+92dx1LkpSQoZUkKSFDK0lSQoZWkqSEDK0kSQkZWkmSEjK0kiQlZGglSUrI0EqSlJChlSQpIUMrSVJChlaSpIQMrSRJCRlaSZISMrSSJCVkaCVJSsjQSpKUkKGVJCkhQytJUkKGVpKkhAytJEkJGVpJkhIytJIkJWRoJUlKyNBKkpSQoZUkKSFDK0lSQoZWkqSEDK0kSQkZWkmSEjK0kiQlZGglSUrI0EqSlJChlSQpIUMrSVJChlaSpIQMrSRJCRlaSZISMrSSJCVkaCVJSsjQSpKUkKGVJCkhQytJUkKGVpKkhAytJEkJGVpJkhIytJIkJWRoJUlKyNBKkpSQoZUkKSFDK0lSQoZWkqSEDK0kSQkZWkmSEjK0kiQlZGglSUrI0EqSlJChlSQpIUMrSVJChlaSpIQMrSRJCRlaSZISMrSSJCVkaCVJSsjQSpKUkKGVJCkhQytJUkKGVpKkhAytJEkJGVpJkhIytJIkJWRoJUlKyNBKkpSQoZUkKSFDK0lSQoZWkqSEDK0kSQkZWkmSEjK0kiQlZGglSUrI0EqSlJChlSQpIUMrSVJChlaSpIQMrSRJCRlaSZISMrSSJCVkaCVJSsjQSpKUkKGVJCkhQytJUkKGVpKkhAytJEkJGVpJkhIytJIkJWRoJUlKyNBKkpSQoZUkKSFDK0lSQoZWkqSEDK0kSQkZWkmSEjK0kiQlZGglSUrI0EqSlJChlSQpIUMrSVJChlaSpIQMrSRJCRlaSZISMrSSJCVkaCVJSsjQSpKUkKGVJCkhQytJUkKGVpKkhAytJEkJGVpJkhIytJIkJWRoJUlKyNBKkpSQoZUkKSFDK0lSQoZWkqSEDK0kSQkZWkmSEjK0kiQlZGglSUrI0EqSlJChlSQpIUMrSVJChlaSpIQMrSRJCRlaSZISMrSSJCVkaCVJSsjQSpKUUPmWHkDS38UYefXVV3n99deZOHEiK1as4NBDD2XUqFFks9ktPZ6kjyHEGD/xlQ4cODBOmzbtE1+vtLVauHAhl156Kffccw/FYpF8Pk8IgVwuR3V1Nbvttht//OMfqaqq2tKjStqIEMKzMcaB7779A3cdhxDahxB2fp/b9/4kh5O2Zb/61a/o06cPt912G4VCgWOOOYZrr72WK6+8koEDB9LY2Mgbb7zB9ddfv6VHlfQxbDS0IYQTgZeBe0MIs0IIg9ZbfEvqwaRtwaJFizj33HPZbrvt6Nu3L/379+ewww4jl8vRvn17TjnlFNq2bUtdXR3jxo3b0uNK+hg+aIv2B8B+McZ9gDOA20II/7R2WUg9mLQtOO2009hzzz35wQ9+QOfOnenTp88GyzOZDL1796ahocHPaKXPqA8KbVmM8S2AGONUYDhwcQjhXOCT/2BX2gY999xzHHnkkYQQ6N69O3PmzNlgealU4pVXXqGqqoq5c+fS3Ny8hSaV9HF9UGhXr//57NroDgOOA/olnkvaJlRWVlIqlQAYPHgwCxYs4P7772fVqlUsWbKEG2+8kdbWVvr06UNFRQV33HHHFp5Y0kf1QaE9i3ftIo4xrgaOBM5MOZS0rejVqxcPPvggpVKJqqoq9ttvP6ZPn86ll17KVVddRceOHbnooouYM2cO/fv3Z/z48Vt6ZEkf0Ua/RxtjfG4jtxcA/1ktfQL23HNPxo0bx49+9CP22GMPZsyYwQknnMCAAQN48803GTduHJdccgllZWVMmTKFI488ckuPLOkj8sxQ0hY0cuRIisUiJ5xwAmVlZbS0tLBw4UKWLFnCz3/+c3bbbTeuvvpqLrroImpra9/zGa6kTz9PWCFtQTFGTjjhBB5//HFaW1vp168fzz77LDFGKisrKRQKDB48mNGjR1MsFrngggs477zzuPLKK7f06JLe5WOdsGK9B1eFEHb75MeStm0hBC688EJWrFhBc3Mzzz//PG3atOGiiy7ipz/9KWPGjGHRokVMmDCBXC5H7969ue6663jzzTe39OiSNtGHhjaEcAwwE5i49u99QggTEs8lbfXmzJnD7rvvzhe+8AVCCOy9995ks1n++Z//mW7dugHQvn17/uVf/oUnnniCpqYm3njjDfr27cvEiRO38PSSNtWmbNH+ENgfqAOIMc4EPpdsImkbUCgUOOigg6irqwMgl8vRoUMHmpub6d69+wb37dChA4VCgTFjxtChQwcaGxuZMmUKs2fP3gKTS/qoNiW0hRjjynfd5gkrpH/AOeecQ319Pf36rflK+kUXXcSoUaPo06cPzz234QH/c+fOpaamhoMOOoi3336bV155hTvvvJP+/fvTq1cvZs6cuQVegaRNtSmXyZsVQjgZKAsh9AHOBaakHUvaetXV1fHrX/+aiy++mPnz59OvXz86d+4MwIgRI7jmmmvI5/P069ePhQsXcv/993PiiSey33770djYyFNPPUVrayvl5eUsXryYwYMH8/TTT9O/f/8t/MokvZ9N2aL9FmvOBNUC/C+wEvh2wpmkrdrjjz9Ojx496Nq1K2VlZRSLxXXLevbsyfnnn88zzzzDVVddxbPPPsvpp5/OfvvtB0D//v3ZYYcd+Pa3v002m+Wcc86hd+/eHHPMMVxxxRWceOKJ3HTTTSxcuJApU6YwduxY+u2yC50qKqguL6d9dTUHH3wwTzzxBCm+cSDpvT5wizaEUAY8GGMcDly0eUaStm7V1dXrzlm81157cdddd7FgwQJ69+4NQJs2bVi+fDnFYpGvf/3rVFRUrHvsG2+8QadOndh5550ZNmwYM2bM4IwzzuD73/8+P7vkEmpDhun33stZpRJlIZCLkZa1j82GQGxs4sU//Ynjhg2jR+/ePPbMM3Tq1GlzvwXSNuUDt2hjjEWgFEKo2UzzSFu9oUOH0tLSwvTp06mqquLMM8/kuuuu47/+67+44YYbuPzyy9l///3J5XLceuut1NfXE2PkpZde4uGHH2b48OEAdO3alZUrV9K+fXuy2SxFoBACb5ZKVIXA3Z06s2+ugvIQOK26Lb/o0JF/bduWfAjkCFQsXMiIQw/dsm+GtA3YlM9o64EXQgiTgIa/3RhjPDfZVNJWLJvN8tBDD3HooYfy4IMP0rZtW/L5PHPnziWXy3H00Uez/fbbM2fOHF588UW+973vEUKgtraWU089lV69ehFjZNq0afTp04fXXnuNYrFIAeiTyfDzDh24YfVqfrZqJc/m85zXth3fbL/m38qHVFaxazbLj1au5JVCgabnnuMvf/kLgwYN+uChJX1sH3pmqBDCae93e4zx1xt7jGeGkj5cPp9nwoQJPPzww3Tp0oWRI0dyzjnn8OKLLxJCYN9992XIkCHMmjWLGTNmkM/nGT16NEuWLOGRRx6hvr6esrIyMpkMmUyGHXv0YNHrrxPzedqEQFkIFIFshP/bqRMDc2t2QTeXSuy1eBEhBHYsK+PNGBk9ejQ33n6717yV/gEbOzOUp2CUPmUWLlzImWeeyZNPPkm3bt1YsmQJ5eXlNDc3E0Igm83yta99jX79+rFkyRLGjh3LW2+9xR577MHuu+/OfffeS5fWVspDhqoQWFIqko+Rqd260y6TYczKOp4r5Pl1x860y2SoL5U4ffk71Bw4hImPPLKlX770mfWxQxtCeJX3+d5sjLH3xh5jaKV/TD6fp7pNG8rKyzn11FMZNGjQulMvHnfccRx44IHr7ltXV8fFF19MLpcjm81SKpX411LkvHbtCSHwdEsLpy1fxvnt2vNPVW046O23+GWHThxSVbVuHfNbCxy5dAl3jx/PMcccsyVesvSZ94+c63ggMGjtz8HAtcDtn+x4ktYXYyQCffv2Zf/996e5uZl58+ZRWVlJr169NrhvbW3tugsQtGnThpbmZr5QUUkIay4nfUBFBSOrqvjvVSsZ8vZb9Cwv58KVKzhp2VLeWfvVou3LymmJkRNGjuT0k05i1apVm/kVS1uvDw1tjPGd9X7+GmP8b+Do9KNJ264YI6VSia5duwKwYsUKampq6NGjB6+88soG9126dCmlUokuXbrQ2NhIWXk5c1tbN7hPc4TasjKe7LYdk7tuxzPdutMvm+U7dSsAGN/UyJBcBdO6bsfqB37H0Yd4NLL0SdmUiwoMWO9nYAjh39i0o5UlfQR1dXWMGzdu3QUDKisrmTlzJq2trXTs2JHVq1dz4IEH8rvf/Y4///nP1NfXM3fuXK6//noOP/xwjjrqKIrFIjFGftWaX7feYow80dLM99vXsH3Zmv/rlofAhe1rmJZv4ZK6Ffx41Uq+376GDpkMV9fU8sL0Z8mFQM8uXRg/fvwWeT+krcWmBPPq9X5vBV4FTkwzjrRtuuXmmzn/7LMZUF1NfanE7MZGmltaKBQKXH755XTt2pVMJsPtt9/OwQcfzL333sudd95JWVkZbdq0oWvXrhSLRVpbW2lubua18nLua2ykKgR+Vb+aDLB9pmyD56wMgcoQeKlQYFznLvQuX3PEcTYE9srmaCWyaMUKzhg9mtvGj+foo92RJX0cmxLar8YYF6x/QwjBq/dIn5CXXnqJC885h/vbtmeXbJYTli4hH6B379506tSJmTNnsv3223PkkUcyY8YMHn30UXK5HGeffTa9e/dm7ty53H777WQyGUqlErlcjsoYuauxgXyMzG8tEGPknqYGBlVUsKjYysx8gfpSiZWlEjtVlK2LLMCqUokXCnkmdenGGcvf4ahcjh98+9uGVvqYNiW0vwUGvM9t+33y40jbnttuuYUvZ3Psks3y+6YmZpaXccyXvsThhx/OT37yE0466aR1RxkfdthhjB07lkwmw+677w7AnnvuySmnnMLYsWPZcccdGThwIG+++SZTp06lVybws5oOnF23nAcaG3m2Jc9bpSIDcjlm5/NUh8BDTc10ydRxUnVblhSLXLayjhFVVWxfXs4xVVU80tzE3Ndf35JvkfSZttHQhhD6suZiAjUhhFHrLWoPVKYeTNqaNDQ0cMoppzBlyhSqq6s54ogj6NGjB6+99hq//e1vKbS0cFtzE435PKUQaNu2LcuWLePtt99m8ODB69YTQuDwww9n7NixG6y/T58+5PN5LrjggnVHG++9997ccccdnN1YTwACUArwVLfu3NZQz4x8nv1zFSwpFfl1YwN3NjZSlQk0lkqcnq0GYHo+z0utrfTovv3mequkrc4HbdHuBowAaoH1v1i3Gvh6wpmkrcpZZ521Lozl5eXU1dVx00030bdvX3r06EFVVRUdO3akpaWFTGMj++yzD9OmTeO+++6jUChQLBbJZP5+3GI+n3/PlXcWLFhAly5d1kUW1oT2zjvvZOSoUYwfN45SSwt9y7P8e90Knsm38Mcu3ehevuY/AQ81NfHDVXUcVlHJC4UCi4pFrlhZx+MtzbQAA3ruyIQJExgxYsQGs0j6cBsNbYxxPDA+hDA4xvjUZpxJ2iq0trbyuc99jrfffpvu3bvzzjvv0NLSQllZGbvuuiuHHXYYIQT22Wcfbr75Ztq3b8/FF19MWdmag5YeeeQRxo8fz6RJk/jSl74EQLFYZPz48axevZr58+ev+4z25ptvpqysjCuvvJIBAwYwbNgwMpkMjY2N1NbW0lIoUAnsUFZGbSbDy4UCV6xeyXW1HcmEwFFVVfxk1UruamygCDxXyFMBdAqBd2Jk7tSpfO/UU7n7sMO47Z57jK30EWzKZ7QzQghns2Y38rpdxjHGM5NNJW0FTj/9dBoaGrj88supra3ljjvuYPbs2QwdOpRCocAvf/lLKisr1wXxpJNOWhdZgG7dulFbW8tjjz3GX/7yF3baaSdmzZpFsVikurqaa6+9lubmZiorK6mpqeHkk08mxsikSZN45ZVX6N27NxUVFdxyyy0QIxM6d6VvLgfA19q2Y+SyJfyhuZkj154hqntZGYdUVnBXYyNHVVYxvZBnWbHI2dXtuL6xnuuzFVwwaRKTJk3iiCOO2BJvqfSZtCn/LL0N2A44Angc6MGa3ceSPsCDDz7IqFGj6NChA/Pnz+fll1/m0ksv5YgjjmDEiBFcdtllNDc3c95551FdXf2ercTy8nLy+Tz5fJ6hQ4ey0047cdZZZ3HiiSdSLBYJIdC9e3fatWvH6tWrWbx4Mb169aJ///7MmzePhx56iB122IFdd92VykxmXWRhzVd7vtKmmknNTQDMKxR4oZDnO+1quKh9DXWxxKQu3dgjm+WWxnq+XFnF/2uoZzQZ7vnf/92s76P0Wbcpod0lxngJ0LD2ij1HA59PO5b02VcsFqmtrQXg+eef5/Of/zyVlX8/jrCmpob+/fsza9YshgwZwsSJEymVSuuWr1ixgvr6eoYPH86wYcMYPnw4vXv35oADDqCmpoYOHTpw/PHHUyqVOO200xg/fjwXX3wxL7/8MkOHDqW2tpYFCxawbNkyYi7HKcuWsHi9M0bVl0q83trKVatWcsI7S7msppZ2mQwHVVTyUqFANgS+3rYdRaBz+ZpTNC4vFfntb37Dq6++urneRukzb1N2HRfW/m9dCGFPYDHQNd1I0tahT58+PPXUU+y6667kcjkaGxvfc5+mpiYqKioYMmQIjz76KJdffjkDBgxg8eLFzJkzh169eq2L9fpqamqYPXs2PXv2ZO+99+ZPf/oTMUa+/OUvs//++wNw7LHHcs0119CtWzd23nlnxo0bx5AV73BPuxp6ZrOMbahnVanEztksd3bqQt+1l8ibmc/Ta+0ZpIpxzdHK9zY0sLhU5Ml8C7tmsxw9fDhX/PznHHfccRvs7pb0XpuyRfurEEIH4BJgAjAb+GnSqaStwL333sv06dO54YYbaNeuHVOmTGHx4sXrls+fP585c+bQv39/GhoaaGhooH///kyePJk+ffowZswYDj74YJ5++ukNtnRXrlzJ7NmzGTRoEO3bt+ett95i6dKl5HK5DS7gXlZWxpFHHsn8+fPp2rUr3/3udyEETli95uIChRgZUVXFi4U82bDm/Mp/bmnmilUr+be27WiJkWtWr6IhRpaUipzTth2VIbB7eTmn1q3kR2d+lROPPZbi2gsTSHp/Xo9WSmjx4sV88Ytf5NVXX6VQWHOGpp133pnW1lbeeOMNDj30UDp27MgDDzxAc3MzpVKJbDbLIYccwogRI4gxcvXVV1MqlRg+fDgNDQ089NBD9OzZk29+85tMnz6d2267jQsuuIBf/OIX/PjHP97gs95Zs2Zx6623ks1mqayspLy8nIULFxJCoLy1lfs7dWH0O0vJhEBTjFSFQO/ycgblKpjU3ETbsOZ7tVWZDCOrqumTLee/V6/iwS7dyMfIsY31/Odtt3lpPYmNXybvQ3cdhxC6Af8JbB9jPCqEsAcwOMY49kMeKm3ztttuO1588UVKpRITJkzggQce4LHHHmPVqlVUV1czdepUMpkMuVyO+vp6ysvLaWpqYtKkSTz66KO0bduW5cuX09raytKlS4E136N98803+d73vkdraytDhw5lxx13pG3btkydOpUDDjgAWPMZ8e9//3saGhrI5XK0tLTQ0tJCmzZt2HfffZkzdSqj3llKx0yG5aUSfcrKWVYqUoiRdiFwbYeO3NvQQD7Aw01NlBEZXlHJmcvfIcZILgSOj/DgffcZWukDbMpntLcANwMXrf17DnA3YGilTZTJZBg5ciQjR47c6H1aWlp44YUXuOuuu3j55ZcpKytj3rx5LF++nF133ZX58+eTzWapra3lK1/5ClOnTuWZZ56hUCgQQuD000/nuuuuY/r06XTu3JmZM2fS0NDAmDFj6NixI/Pnz+cXv/gFzc3NtLS00JDJ8I227fhNUyOPdduO7cvKKcTIf6xayYuFAkdUVTGhuZkL27VjIk3cUF9Pn/IsO5SVrTsxxopMhrY1NZvpXZQ+mzYltJ1jjL8JIXwfIMbYGkLwQxnpE1ZRUcHAgQMZOHDDPU/Dhw/nqaeeYtSoUUydOpW33nqLV199lVNPPZV9992XG2+8kYEDB7LLLrvwwx/+kLvvvpunn36aLl26UF5eTqdOnQDYZZddOP7443nsscdYsWIF+WKRJ/J5Ll7v8nnZEPhe+xr6L17EM0uXMqa2lhvr6+mYybBXNsf/qVvB2e3aAfBaayu3Nzcx+YwzNu8bJX3GbEpoG0IInYAIEEI4AFiZdCpJ60yePJlDDz2UCRMmEEIgn8/zhz/8gYkTJ5LNZimVSlxzzTXU1NTQ2tpKdXU1n//853n66ac56KCDNljXjjvuSKlU4vzzz2fMmDHMWraM7cvee/m8tms/qx2zciXHVFUxvrGBf+/Uni8seZu76+v5U0sLT+VbGLD//vTv339zvh3SZ86mHHX8HdYcbbxzCOHPwK3At5JOJWmdTCbDo48+Sl1dHU8++SQXXnjhugOnQgh07dqVGCONjY2sWrWKRYsW8dJLL1EoFNhnn302WNfzzz9Pz549yWQyDB48mFbgpvr6De7zXD5PY4zsn8txYft2PJNv4att29ExU0YGqM4Ejm/ThnPbtqPPzjtvtvdB+qzaaGhDCD0BYozTgaHAEOAbQL8Y4/ObZzxJf1NZWcnAgQP56U9/SlNT05ojhZuaWLZsGZlMhmKxSHl5OdlslqVLlzJs2DBuueUWXnjhBZYuXcqkSZN4+OGHOfzww4E1R0THGHm4uYlvrVjO5OYmfrl6FSe/s5TmGLmnqZE/NDdzfrv2fKdde35Zv5qdysoZXFnFIRWV3J8JjDr55C38rkiffh+06/h+/n4d2rtjjKPTjyNpU1RWVtKSz/Pd736X//mf/6GlpYWddtqJ448/nltvvZUVK1YwaNAgevbsyYMPPkhdXR1du3alQ4cO646EnjZt2rpA/76pkUebmygCq2OkE7AyRlaUSszK57mjoYEFra0sLxVpAI5orGfYiBHrLnYgaeM2+j3aEMKMGOO+7/59U/g9Wmnzmjx5MkcffTS77bYbX/ziF5k8eTJ//etf+cY3vsGOO+7IggULuP7662lpaaGqqoqmpiZCCFx22WW89tpr3HrTTcRCgV3Ls/y1tcBqoAhkgRKQC4FMWRkjTz6ZHbp350sjRnDggQducFk+aVu3se/RflBop8cYB7z7901haKXNb968eRx11FEsWrSIGCPNzc1ks1kKhQIVFRWUl5dTW1tLhw4dGD16NOeeey4dOnQA1nzn9o9//CPz5s1jr7324uCDD2bRokX85je/Yf78+Rx++OFei1b6EB8ntEWggTWnOq0C/nai1gDEGGP7jT2ZoZU+HWKM5PN5crmcW59SYh/5zFAxRs8ULn3GhRCoqKjY0mNI2zT3A0mSlJChlSQpIUMrSVJChlaSpIQMrSRJCRlaSZISMrSSJCVkaCVJSsjQSpKUkKGVJCkhQytJUkKGVpKkhAytJEkJGVpJkhIytJIkJWRoJUlKyNBKkpSQoZUkKSFDK0lSQoZWkqSEDK0kSQkZWkmSEjK0kiQlZGglSUrI0EqSlJChlSQpIUMrSVJChlaSpIQMrSRJCRlaSZISMrSSJCVkaCVJSsjQSpKUkKGVJCkhQytJUkKGVpKkhAytJEkJGVpJkhIytJIkJWRoJUlKyNBKkpSQoZUkKSFDK0lSQoZWkqSEDK0kSQkZWkmSEjK0kiQlZGglSUrI0EqSlJChlSQpIUMrSVJChlaSpIQMrSRJCRlaSZISMrSSJCVkaCVJSsjQSpKUkKGVJCkhQytJUkKGVpKkhAytJEkJGVpJkhIytJIkJWRoJUlKyNBKkpSQoZUkKSFDK0lSQoZWkqSEDK0kSQkZWkmSEjK0kiQlZGglSUrI0EqSlJChlSQpIUMrSVJChlaSpIQMrSRJCRlaSZISMrSSJCVkaCVJSsjQSpKUkKGVJCkhQytJUkKGVpKkhAytJEkJGVpJkhIytJIkJWRoJUlKyNBKkpSQoZUkKSFDK0lSQoZWkqSEDK0kSQkZWkmSEjK0kiQlZGglSUrI0EqSlJChlSQpIUMrSVJChlaSpIQMrSRJCRlaSZISMrSSJCVkaCVJSsjQSpKUkKGVJCkhQytJUkKGVpKkhAytJEkJGVpJkhIytJIkJWRoJUlKyNBKkpSQoZUkKSFDK0lSQoZWkqSEDK0kSQkZWkmSEjK0kiQlZGglSUrI0EqSlJChlSQpIUMrSVJChlaSpIQMrSRJCRlaSZISMrSSJCVkaCVJSsjQSpKUkKGVJCkhQytJUkKGVpKkhAytJEkJGVpJkhIytJIkJWRoJUlKyNBKkpSQoZUkKaEQY/zkVxrCUuD1T3zFkiR9eu0UY+zy7huThFaSJK3hrmNJkhIytJIkJWRopS0ghFAMIcxc76fXx1jHyBDCHgnG+9v6J4YQ6kIIv0v1HNK2oHxLDyBto5pijPv8g+sYCfwOmL2pDwghlMcYWzfx7lcBbYBvfPTRJP2NW7TSp0QIYb8QwuMhhGdDCA+HELqvvf3rIYS/hBCeCyHcG0JoE0IYAhwLXLV2i3jnEMJjIYSBax/TOYTw2trfTw8hTAghPAJMDiFUhxBuCiFMDSHMCCEc937zxBgnA6s3y4uXtmKGVtoyqtbbbTwuhJAFrgOOjzHuB9wE/Mfa+94XYxwUY+wPvAR8NcY4BZgAXBhj3CfGOP9Dnm/A2nUPBS4CHokx7g8MZ02sqxO8Rkm461jaUjbYdRxC2BPYE5gUQgAoA95au3jPEMIVQC3QFnj4YzzfpBjj8rW/Hw4cG0K4YO3flUBP1kRc0ifM0EqfDgGYFWMc/D7LbgFGxhifCyGcDgzbyDpa+fteqsp3LWt413ONjjG+8rGnlbTJ3HUsfTq8AnQJIQwGCCFkQwj91i5rB7y1dvfyKes9ZvXaZX/zGrDf2t+P/4Dnehj4Vli76RxC2PcfH1/Sxhha6VMgxphnTRyvDCE8B8wEhqxdfAnwDPBn4OX1HnYXcOHaA5p2Bn4GnBVCmAF0/oCnuxzIAs+HEGat/fs9QghPAvcAh4YQ3gwhHPFxX5+0LfMUjJIkJeQWrSRJCRlaSZISMrSSJCVkaCVJSsjQSpKUkKGVJCkhQytJUkKGVpKkhP4/bhMnkGvR/H4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# only plots two features\n",
    "# plot_two_features_classification(df.iloc[:,0],df.iloc[:,2], df.iloc[:,4], 'figures/'+dataset_name+'.png')\n",
    "plot_two_features_classification(dataset.X[:,0],dataset.X[:,1], dataset.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9189671c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------create model-----------\n",
      "param count is : 15\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "end of run - train loss array is: [0.600919848078059, 0.34986473631484916, 0.31838486701304003, 0.31317217426233557, 0.3116855215279075, 0.30556051820757696, 0.3020661837626545, 0.3000403804529954, 0.29867843127419086, 0.29767909532747266, 0.2968992739195077, 0.2962605306550331, 0.29571606829692115, 0.29523649626079923, 0.2948027752545545]\n",
      "end of run - val loss array is: [0.4163892174209082, 0.33860927035847965, 0.3338927134560521, 0.31768979342243675, 0.3028086773307559, 0.30045557827953195, 0.30004127752739007, 0.29995447385218055, 0.2999975797159238, 0.3000963579121028, 0.30021284695487094, 0.3003287672200895, 0.30043703243033326, 0.3005364192225821, 0.30062827573749096]\n",
      "end of run - val accuracy is: [0.8036363636363636, 0.88, 0.8727272727272726, 0.8727272727272726, 0.88, 0.8836363636363637, 0.8836363636363637, 0.8836363636363637, 0.8836363636363637, 0.8836363636363637, 0.8836363636363637, 0.88, 0.88, 0.88, 0.88]\n",
      "--------end fitting-----------\n",
      "\n",
      "--------create model (without extra layer) -----------\n",
      "param count is : 9\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "test_dl_is_not None\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "Not Using backend\n",
      "end of run - train loss array is: [0.5987981831811117, 0.37338053515476405, 0.327941510893794, 0.32071880605944303, 0.31857113717158336, 0.317249261212291, 0.3162536050038828, 0.3154289984892931, 0.31469770457355156, 0.31401795063429905, 0.31336671376688874, 0.31273073508802307, 0.312101948780123, 0.31147519927071743, 0.3108470950562166]\n",
      "end of run - val loss array is: [0.43576716921777253, 0.34645834648608276, 0.33440840887556816, 0.33373231504823375, 0.33382215335603865, 0.3341279793279845, 0.33455296702602455, 0.3350223785335484, 0.33548404366024415, 0.33590596327380423, 0.33626954947948606, 0.3365645705518187, 0.33678604247113286, 0.33693233560273245, 0.33700399250803165]\n",
      "end of run - val accuracy is: [0.8181818181818185, 0.869090909090909, 0.8690909090909089, 0.8690909090909089, 0.8690909090909089, 0.8690909090909089, 0.8727272727272726, 0.8690909090909089, 0.8690909090909089, 0.8690909090909089, 0.8690909090909089, 0.8763636363636362, 0.8763636363636362, 0.8799999999999999, 0.8799999999999999]\n",
      "--------end fitting-----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn1, cnn2 = create_cnn_and_fit_and_store_result(save_path, dataset, n, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "039bbb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------create model-----------\n",
      "param count is : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:268: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:210.)\n",
      "  predictions = T.tensor([np.array(result)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "end of run - train loss array is: [0.7715942015936307, 0.7314699578886495, 0.6924856435414799, 0.7012571307445291, 0.6878334499555401, 0.6914237908403901, 0.671529353075923, 0.6805996973007521, 0.6952005526725713, 0.6973770608110577, 0.6675136709782132, 0.6840946847153727, 0.6852933587939931, 0.6659795895398581, 0.6609848643910007]\n",
      "end of run - val loss array is: [0.8507534626064294, 0.8469365279808531, 0.82849902684393, 0.8608325979209149, 0.898811117974704, 0.8192918515116198, 0.8533014598301862, 0.8809779393981028, 0.8374146101594269, 0.8598791979093372, 0.8886161652318126, 0.8478489581972407, 0.8435638343326265, 0.8747851242023272, 0.8285161060712549]\n",
      "end of run - val accuracy is: [0.5454545454545455, 0.6072727272727273, 0.6000000000000002, 0.5890909090909092, 0.6072727272727272, 0.5818181818181819, 0.5890909090909093, 0.6072727272727272, 0.5818181818181819, 0.5890909090909092, 0.6254545454545456, 0.6072727272727272, 0.6036363636363639, 0.610909090909091, 0.68]\n",
      "--------end fitting-----------\n",
      "\n",
      "--------create model-----------\n",
      "param count is : 7\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n",
      "Using backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:87: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if key[i] is '0':\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:96: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if key[measuring_qubit] is '0':\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:158: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:160: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"probabilities_per_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:162: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"measure_one_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:170: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:196: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:198: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"probabilities_per_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:206: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:87: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if key[i] is '0':\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:96: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if key[measuring_qubit] is '0':\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:158: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:160: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"probabilities_per_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:162: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"measure_one_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:170: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:196: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:198: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"probabilities_per_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:206: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:87: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if key[i] is '0':\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:96: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if key[measuring_qubit] is '0':\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:158: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:160: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"probabilities_per_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:162: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"measure_one_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:170: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:196: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:198: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"probabilities_per_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:206: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:87: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if key[i] is '0':\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:96: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if key[measuring_qubit] is '0':\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:158: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:160: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"probabilities_per_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:162: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"measure_one_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:170: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:196: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:198: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"probabilities_per_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:206: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:87: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if key[i] is '0':\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:96: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if key[measuring_qubit] is '0':\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:158: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:160: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"probabilities_per_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:162: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"measure_one_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:170: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:196: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:198: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"probabilities_per_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:206: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:87: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if key[i] is '0':\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:96: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if key[measuring_qubit] is '0':\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:158: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:160: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"probabilities_per_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:162: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"measure_one_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:170: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:196: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:198: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif self.post_process is \"probabilities_per_qubit\":\n",
      "c:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:206: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.post_process is \"parity\":\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\fit_models_banknote.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=103'>104</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m acc\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=105'>106</a>\u001b[0m create_qnn_and_fit_and_store_result_(save_path, circuit_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mZzFeatureMapRealAmplitudeCircuit\u001b[39m\u001b[39m\"\u001b[39m, dataset\u001b[39m=\u001b[39mdataset, n\u001b[39m=\u001b[39mn, epochs\u001b[39m=\u001b[39mepochs)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=107'>108</a>\u001b[0m create_qnn_and_fit_and_store_result_(save_path, circuit_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mCombinedQnn\u001b[39;49m\u001b[39m\"\u001b[39;49m, dataset\u001b[39m=\u001b[39;49mdataset, n\u001b[39m=\u001b[39;49mn, epochs\u001b[39m=\u001b[39;49mepochs)\n",
      "\u001b[1;32mc:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\fit_models_banknote.ipynb Cell 5'\u001b[0m in \u001b[0;36mcreate_qnn_and_fit_and_store_result_\u001b[1;34m(save_path, circuit_type, dataset, n, epochs, batch_size, loss_obj, test_size, lrn)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mparam count is :\u001b[39m\u001b[39m\"\u001b[39m, count_parameters(qnn1))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=10'>11</a>\u001b[0m train_dl, test_dl \u001b[39m=\u001b[39m create_train_test_dataloader(dataset, batch_size\u001b[39m=\u001b[39mbatch_size, test_size\u001b[39m=\u001b[39mtest_size)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=12'>13</a>\u001b[0m loss_array, _, acc_array \u001b[39m=\u001b[39m train_on_dl_(qnn1, train_dl, test_dl, epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=13'>14</a>\u001b[0m                                        loss_obj\u001b[39m=\u001b[39;49mloss_obj, optimizer\u001b[39m=\u001b[39;49mT\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam(qnn1\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39;49mlrn))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=15'>16</a>\u001b[0m np\u001b[39m.\u001b[39msave(save_path \u001b[39m+\u001b[39m circuit_type \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_bs\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(batch_size) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_loss.npy\u001b[39m\u001b[39m'\u001b[39m, loss_array)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=16'>17</a>\u001b[0m np\u001b[39m.\u001b[39msave(save_path \u001b[39m+\u001b[39m circuit_type \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_bs\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(batch_size) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_accuracy.npy\u001b[39m\u001b[39m'\u001b[39m, acc_array)\n",
      "\u001b[1;32mc:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\fit_models_banknote.ipynb Cell 5'\u001b[0m in \u001b[0;36mtrain_on_dl_\u001b[1;34m(model, train_loader, test_dl, epochs, optimizer, verbose, loss_obj)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=45'>46</a>\u001b[0m \u001b[39m# print(\"loss:\", loss)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=46'>47</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=47'>48</a>\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=48'>49</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=49'>50</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=50'>51</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=51'>52</a>\u001b[0m total_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\function.py:253\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/autograd/function.py?line=248'>249</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mImplementing both \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbackward\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mvjp\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for a custom \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/autograd/function.py?line=249'>250</a>\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mFunction is not allowed. You should only implement one \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/autograd/function.py?line=250'>251</a>\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mof them.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/autograd/function.py?line=251'>252</a>\u001b[0m user_fn \u001b[39m=\u001b[39m vjp_fn \u001b[39mif\u001b[39;00m vjp_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m Function\u001b[39m.\u001b[39mvjp \u001b[39melse\u001b[39;00m backward_fn\n\u001b[1;32m--> <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/autograd/function.py?line=252'>253</a>\u001b[0m \u001b[39mreturn\u001b[39;00m user_fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:287\u001b[0m, in \u001b[0;36mQnnCircuitFunction.backward\u001b[1;34m(ctx, grad_out)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=284'>285</a>\u001b[0m shift_right \u001b[39m=\u001b[39m direction \u001b[39m*\u001b[39m ctx\u001b[39m.\u001b[39mshift\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=285'>286</a>\u001b[0m shift_left \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m direction \u001b[39m*\u001b[39m ctx\u001b[39m.\u001b[39mshift\n\u001b[1;32m--> <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=286'>287</a>\u001b[0m expectation_right \u001b[39m=\u001b[39m ctx\u001b[39m.\u001b[39;49mqnn\u001b[39m.\u001b[39;49mpredict_with_backend(\u001b[39minput\u001b[39;49m, params\u001b[39m=\u001b[39;49mctx\u001b[39m.\u001b[39;49mweight \u001b[39m+\u001b[39;49m shift_right)\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=287'>288</a>\u001b[0m expectation_left \u001b[39m=\u001b[39m ctx\u001b[39m.\u001b[39mqnn\u001b[39m.\u001b[39mpredict_with_backend(\u001b[39minput\u001b[39m, params\u001b[39m=\u001b[39mctx\u001b[39m.\u001b[39mweight \u001b[39m+\u001b[39m shift_left)\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=288'>289</a>\u001b[0m gradient \u001b[39m=\u001b[39m T\u001b[39m.\u001b[39mtensor([expectation_right]) \u001b[39m-\u001b[39m T\u001b[39m.\u001b[39mtensor([expectation_left])\n",
      "File \u001b[1;32mc:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:189\u001b[0m, in \u001b[0;36mQnn.predict_with_backend\u001b[1;34m(self, x_list, params, backend, shots)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=186'>187</a>\u001b[0m circ_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcircuit\u001b[39m.\u001b[39massign_parameters(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_data_dict(params, x))\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=187'>188</a>\u001b[0m circ_\u001b[39m.\u001b[39mmeasure_all()\n\u001b[1;32m--> <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=188'>189</a>\u001b[0m counts \u001b[39m=\u001b[39m run_circuit(circ_, backend, shots)\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=189'>190</a>\u001b[0m qc_list \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [counts]\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=190'>191</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount_of_runs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py:104\u001b[0m, in \u001b[0;36mrun_circuit\u001b[1;34m(circuit, backend, shots)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=101'>102</a>\u001b[0m compiled_circuit \u001b[39m=\u001b[39m transpile(circuit, backend)\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=102'>103</a>\u001b[0m job \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mrun(compiled_circuit, shots\u001b[39m=\u001b[39mshots)\n\u001b[1;32m--> <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=103'>104</a>\u001b[0m result \u001b[39m=\u001b[39m job\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=104'>105</a>\u001b[0m \u001b[39m# counts = result.get_counts(compiled_circuit)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/QnnTorchConnector.py?line=105'>106</a>\u001b[0m counts \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mget_counts()\n",
      "File \u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\qiskit\\providers\\aer\\jobs\\utils.py:41\u001b[0m, in \u001b[0;36mrequires_submit.<locals>._wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/qiskit/providers/aer/jobs/utils.py?line=38'>39</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_future \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/qiskit/providers/aer/jobs/utils.py?line=39'>40</a>\u001b[0m     \u001b[39mraise\u001b[39;00m JobError(\u001b[39m\"\u001b[39m\u001b[39mJob not submitted yet!. You have to .submit() first!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/qiskit/providers/aer/jobs/utils.py?line=40'>41</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\qiskit\\providers\\aer\\jobs\\aerjob.py:78\u001b[0m, in \u001b[0;36mAerJob.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/qiskit/providers/aer/jobs/aerjob.py?line=59'>60</a>\u001b[0m \u001b[39m@requires_submit\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/qiskit/providers/aer/jobs/aerjob.py?line=60'>61</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresult\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/qiskit/providers/aer/jobs/aerjob.py?line=61'>62</a>\u001b[0m     \u001b[39m# pylint: disable=arguments-differ\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/qiskit/providers/aer/jobs/aerjob.py?line=62'>63</a>\u001b[0m     \u001b[39m\"\"\"Get job result. The behavior is the same as the underlying\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/qiskit/providers/aer/jobs/aerjob.py?line=63'>64</a>\u001b[0m \u001b[39m    concurrent Future objects,\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/qiskit/providers/aer/jobs/aerjob.py?line=64'>65</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/qiskit/providers/aer/jobs/aerjob.py?line=75'>76</a>\u001b[0m \u001b[39m        concurrent.futures.CancelledError: if job cancelled before completed.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/qiskit/providers/aer/jobs/aerjob.py?line=76'>77</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/qiskit/providers/aer/jobs/aerjob.py?line=77'>78</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py:435\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/concurrent/futures/_base.py?line=431'>432</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/concurrent/futures/_base.py?line=432'>433</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/concurrent/futures/_base.py?line=434'>435</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/concurrent/futures/_base.py?line=436'>437</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/concurrent/futures/_base.py?line=437'>438</a>\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/threading.py?line=309'>310</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/threading.py?line=310'>311</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/threading.py?line=311'>312</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/threading.py?line=312'>313</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/threading.py?line=313'>314</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_qnn_and_fit_and_store_result_(save_path, circuit_type, dataset, n, epochs,\n",
    "                                        batch_size=10, loss_obj=T.nn.BCELoss(), test_size=0.2, lrn=0.05):\n",
    "\n",
    "    print(\"--------create model-----------\")\n",
    "\n",
    "    circuit1 = CircuitFactory().provide(circuit_type, n)\n",
    "    qnn1 = QnnTorchConnector(Qnn(circuit1))\n",
    "\n",
    "    print(\"param count is :\", count_parameters(qnn1))\n",
    "\n",
    "    train_dl, test_dl = create_train_test_dataloader(dataset, batch_size=batch_size, test_size=test_size)\n",
    "\n",
    "    loss_array, _, acc_array = train_on_dl_(qnn1, train_dl, test_dl, epochs=epochs,\n",
    "                                           loss_obj=loss_obj, optimizer=T.optim.Adam(qnn1.parameters(), lr=lrn))\n",
    "\n",
    "    np.save(save_path + circuit_type + '_bs' + str(batch_size) + '_loss.npy', loss_array)\n",
    "    np.save(save_path + circuit_type + '_bs' + str(batch_size) + '_accuracy.npy', acc_array)\n",
    "    print(\"--------end fitting-----------\\n\")\n",
    "\n",
    "    return qnn1\n",
    "\n",
    "def train_on_dl_(model, train_loader, test_dl=None, epochs=100, optimizer=None,\n",
    "                verbose=0, loss_obj=T.nn.BCELoss()):\n",
    "    loss_list_val = []\n",
    "    loss_list_train = []\n",
    "    acc_list_val = []\n",
    "\n",
    "    if optimizer is None:\n",
    "        optimizer = T.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = []\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.type(T.DoubleTensor)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "            target = T.reshape(target, [1, -1])\n",
    "            output = T.reshape(output, [1, -1])\n",
    "            # print(output)\n",
    "            # print(target)\n",
    "\n",
    "            # Calculating loss\n",
    "            loss = loss_obj(output, target)\n",
    "            # print(\"loss:\", loss)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "        epoch_train_loss = sum(total_loss) / len(total_loss)\n",
    "        loss_list_train.append(epoch_train_loss)\n",
    "\n",
    "        if verbose == 1:\n",
    "            print(\"training loss for epoch \", epoch, \" is :\", loss_list_val[-1])\n",
    "        if test_dl is not None:\n",
    "            model.eval()\n",
    "            val_loss, val_accuracy = eval_on_dataloader_(model, test_dl, loss_obj)\n",
    "            loss_list_val.append(val_loss)\n",
    "            acc_list_val.append(val_accuracy)\n",
    "\n",
    "    print(\"end of run - train loss array is:\", loss_list_train)\n",
    "    print(\"end of run - val loss array is:\", loss_list_val)\n",
    "    if val_accuracy is not None:\n",
    "        print(\"end of run - val accuracy is:\", acc_list_val)\n",
    "\n",
    "    return loss_list_val, loss_list_train, acc_list_val\n",
    "\n",
    "\n",
    "def eval_on_dataloader_(model, data_loader, loss_obj=T.nn.BCELoss()):  # TODO inefficient as it predicts twice...\n",
    "    loss = compute_loss_(model, data_loader, loss_obj)\n",
    "    acc = accuracy_(model, data_loader)\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def compute_loss_(model, dataloader, loss_obj=T.nn.BCELoss()):\n",
    "    total_loss = 0\n",
    "    for i, (inputs, targets) in enumerate(dataloader):\n",
    "        if isinstance(model.qnn, Qnn):\n",
    "            print(\"Using backend\")\n",
    "            output = T.tensor(model.qnn.predict_with_backend(inputs))\n",
    "        else:\n",
    "            print(\"Not Using backend\")\n",
    "            output = model(inputs)\n",
    "        target = T.reshape(targets, [1, -1])\n",
    "        output = T.reshape(output, [1, -1])\n",
    "        total_loss += loss_obj(output, target).item() / len(dataloader)\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def accuracy_(model, dataloader):\n",
    "    acc = 0\n",
    "    for i, (inputs, targets) in enumerate(dataloader):\n",
    "        if isinstance(model, Qnn):\n",
    "            output = T.tensor(model.predict_with_backend(inputs))\n",
    "        else:\n",
    "            output = model(inputs)\n",
    "        output = T.reshape(output, [1, -1])\n",
    "        targets = T.reshape(targets, [1, -1])\n",
    "        acc += T.sum(T.round(output) == T.round(targets)).numpy() / len(dataloader.dataset)\n",
    "    return acc\n",
    "\n",
    "create_qnn_and_fit_and_store_result_(save_path, circuit_type=\"ZzFeatureMapRealAmplitudeCircuit\", dataset=dataset, n=n, epochs=epochs)\n",
    "\n",
    "create_qnn_and_fit_and_store_result_(save_path, circuit_type=\"CombinedQnn\", dataset=dataset, n=n, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f6c8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------create model-----------\n",
      "param count is : 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\fit_models_banknote.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000004?line=0'>1</a>\u001b[0m create_qnn_and_fit_and_store_result(save_path, circuit_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mZzFeatureMapRealAmplitudeCircuit\u001b[39;49m\u001b[39m\"\u001b[39;49m, dataset\u001b[39m=\u001b[39;49mdataset, n\u001b[39m=\u001b[39;49mn, epochs\u001b[39m=\u001b[39;49mepochs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000004?line=2'>3</a>\u001b[0m create_qnn_and_fit_and_store_result(save_path, circuit_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCombinedQnn\u001b[39m\u001b[39m\"\u001b[39m, dataset\u001b[39m=\u001b[39mdataset, n\u001b[39m=\u001b[39mn, epochs\u001b[39m=\u001b[39mepochs)\n",
      "\u001b[1;32mc:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\fit_models_banknote.ipynb Cell 5'\u001b[0m in \u001b[0;36mcreate_qnn_and_fit_and_store_result\u001b[1;34m(save_path, circuit_type, dataset, n, epochs, batch_size, loss_obj, test_size, lrn)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=6'>7</a>\u001b[0m qnn1 \u001b[39m=\u001b[39m QnnTorchConnector(Qnn(circuit1))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mparam count is :\u001b[39m\u001b[39m\"\u001b[39m, count_parameters(qnn1))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=10'>11</a>\u001b[0m train_dl, test_dl \u001b[39m=\u001b[39m create_train_test_dataloader(dataset, batch_size\u001b[39m=\u001b[39;49mbatch_size, test_size\u001b[39m=\u001b[39;49mtest_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=12'>13</a>\u001b[0m loss_array, _, acc_array \u001b[39m=\u001b[39m train_on_dl_(qnn1, train_dl, test_dl, epochs\u001b[39m=\u001b[39mepochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=13'>14</a>\u001b[0m                                        loss_obj\u001b[39m=\u001b[39mloss_obj, optimizer\u001b[39m=\u001b[39mT\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(qnn1\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlrn))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/fit_models_banknote.ipynb#ch0000008?line=15'>16</a>\u001b[0m np\u001b[39m.\u001b[39msave(save_path \u001b[39m+\u001b[39m circuit_type \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_bs\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(batch_size) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_loss.npy\u001b[39m\u001b[39m'\u001b[39m, loss_array)\n",
      "File \u001b[1;32mc:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\Utils.py:168\u001b[0m, in \u001b[0;36mcreate_train_test_dataloader\u001b[1;34m(dataset, batch_size, test_size, random_state)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/Utils.py?line=165'>166</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_train_test_dataloader\u001b[39m(dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m):\n\u001b[1;32m--> <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/Utils.py?line=167'>168</a>\u001b[0m     train, test \u001b[39m=\u001b[39m train_test_split(dataset, test_size\u001b[39m=\u001b[39;49mtest_size, random_state\u001b[39m=\u001b[39;49mrandom_state)\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/Utils.py?line=168'>169</a>\u001b[0m     train_dl \u001b[39m=\u001b[39m T\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(train, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    <a href='file:///c%3A/Programs/pc/Python/tcc/Testing_Quantum_Neural_Net/classes/Utils.py?line=169'>170</a>\u001b[0m     test_dl \u001b[39m=\u001b[39m T\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(test, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2199\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2192'>2193</a>\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test,\n\u001b[0;32m   <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2193'>2194</a>\u001b[0m                  train_size\u001b[39m=\u001b[39mn_train,\n\u001b[0;32m   <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2194'>2195</a>\u001b[0m                  random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m   <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2196'>2197</a>\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[1;32m-> <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2198'>2199</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(chain\u001b[39m.\u001b[39;49mfrom_iterable((_safe_indexing(a, train),\n\u001b[0;32m   <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2199'>2200</a>\u001b[0m                                  _safe_indexing(a, test)) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m arrays))\n",
      "File \u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2199\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2192'>2193</a>\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test,\n\u001b[0;32m   <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2193'>2194</a>\u001b[0m                  train_size\u001b[39m=\u001b[39mn_train,\n\u001b[0;32m   <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2194'>2195</a>\u001b[0m                  random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m   <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2196'>2197</a>\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[1;32m-> <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2198'>2199</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(chain\u001b[39m.\u001b[39mfrom_iterable((_safe_indexing(a, train),\n\u001b[0;32m   <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2199'>2200</a>\u001b[0m                                  _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays))\n",
      "File \u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\__init__.py:346\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/__init__.py?line=343'>344</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/__init__.py?line=344'>345</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/__init__.py?line=345'>346</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\__init__.py:205\u001b[0m, in \u001b[0;36m_list_indexing\u001b[1;34m(X, key, key_dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/__init__.py?line=202'>203</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(compress(X, key))\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/__init__.py?line=203'>204</a>\u001b[0m \u001b[39m# key is a integer array-like of key\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/__init__.py?line=204'>205</a>\u001b[0m \u001b[39mreturn\u001b[39;00m [X[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m key]\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1508\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:1086\u001b[0m, in \u001b[0;36mPyDB.enable_tracing\u001b[1;34m(self, thread_trace_func, apply_to_all_threads)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=1082'>1083</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=1083'>1084</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_thread_trace_func\u001b[39m.\u001b[39mthread_trace_func \u001b[39m=\u001b[39m thread_trace_func\n\u001b[1;32m-> <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=1085'>1086</a>\u001b[0m pydevd_tracing\u001b[39m.\u001b[39;49mSetTrace(thread_trace_func)\n\u001b[0;32m   <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=1086'>1087</a>\u001b[0m \u001b[39mif\u001b[39;00m IS_CPYTHON \u001b[39mand\u001b[39;00m apply_to_all_threads:\n\u001b[0;32m   <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd.py?line=1087'>1088</a>\u001b[0m     pydevd_tracing\u001b[39m.\u001b[39mset_trace_to_threads(thread_trace_func)\n",
      "File \u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_tracing.py:77\u001b[0m, in \u001b[0;36mSetTrace\u001b[1;34m(tracing_func)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=73'>74</a>\u001b[0m _last_tracing_func_thread_local\u001b[39m.\u001b[39mtracing_func \u001b[39m=\u001b[39m tracing_func\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=75'>76</a>\u001b[0m \u001b[39mif\u001b[39;00m tracing_func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=76'>77</a>\u001b[0m     \u001b[39mif\u001b[39;00m set_trace_to_threads(tracing_func, thread_idents\u001b[39m=\u001b[39;49m[thread\u001b[39m.\u001b[39;49mget_ident()], create_dummy_thread\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=77'>78</a>\u001b[0m         \u001b[39m# If we can use our own tracer instead of the one from sys.settrace, do it (the reason\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=78'>79</a>\u001b[0m         \u001b[39m# is that this is faster than the Python version because we don't call\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=79'>80</a>\u001b[0m         \u001b[39m# PyFrame_FastToLocalsWithError and PyFrame_LocalsToFast at each event!\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=80'>81</a>\u001b[0m         \u001b[39m# (the difference can be huge when checking line events on frames as the\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=81'>82</a>\u001b[0m         \u001b[39m# time increases based on the number of local variables in the scope)\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=82'>83</a>\u001b[0m         \u001b[39m# See: InternalCallTrampoline (on the C side) for details.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=83'>84</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=85'>86</a>\u001b[0m \u001b[39m# If it didn't work (or if it was None), use the Python version.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_tracing.py:345\u001b[0m, in \u001b[0;36mset_trace_to_threads\u001b[1;34m(tracing_func, thread_idents, create_dummy_thread)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=342'>343</a>\u001b[0m start_new_thread \u001b[39m=\u001b[39m pydev_monkey\u001b[39m.\u001b[39mget_original_start_new_thread(thread)\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=343'>344</a>\u001b[0m start_new_thread(increase_tracing_count, ())\n\u001b[1;32m--> <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=344'>345</a>\u001b[0m proceed\u001b[39m.\u001b[39;49macquire()  \u001b[39m# Only proceed after the release() is done.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=345'>346</a>\u001b[0m proceed \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Henrique%20Joaquim/AppData/Local/Programs/Python/Python39/lib/site-packages/debugpy/_vendored/pydevd/pydevd_tracing.py?line=347'>348</a>\u001b[0m \u001b[39m# Note: The set_trace_func is not really used anymore in the C side.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "create_qnn_and_fit_and_store_result(save_path, circuit_type=\"ZzFeatureMapRealAmplitudeCircuit\", dataset=dataset, n=n, epochs=epochs)\n",
    "\n",
    "create_qnn_and_fit_and_store_result(save_path, circuit_type=\"CombinedQnn\", dataset=dataset, n=n, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed91ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------create model-----------\n",
      "param count is : 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-fe903e99c41a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcreate_hybridqnn_and_fit_and_store_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ZzFeatureMapRealAmplitudeCircuit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcreate_hybridqnn_and_fit_and_store_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"CombinedQnn\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\Utils.py\u001b[0m in \u001b[0;36mcreate_hybridqnn_and_fit_and_store_result\u001b[1;34m(save_path, circuit_type, dataset, n, epochs, batch_size, loss_obj, test_size, lrn)\u001b[0m\n\u001b[0;32m    205\u001b[0m                                    binary_classification=True if isinstance(loss_obj, T.nn.BCELoss) else False)\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"param count is :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqnn1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m     \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_train_test_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\Utils.py\u001b[0m in \u001b[0;36mtrain_on_dl\u001b[1;34m(model, train_loader, test_dl, epochs, optimizer, verbose, loss_obj)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# Backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\function.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    251\u001b[0m                                \"of them.\")\n\u001b[0;32m    252\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(ctx, grad_out)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mfinal_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[0mdirection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Programs\\pc\\Python\\tcc\\Testing_Quantum_Neural_Net\\classes\\QnnTorchConnector.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x_list, params)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# predicts via statevector evolve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Henrique Joaquim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    702\u001b[0m                           \u001b[1;34m'iterations executed (and might lead to errors or silently give '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m                           'incorrect results).', category=torch.jit.TracerWarning, stacklevel=2)\n\u001b[1;32m--> 704\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "create_hybridqnn_and_fit_and_store_result_(save_path, \"ZzFeatureMapRealAmplitudeCircuit\", dataset, n, epochs)\n",
    "\n",
    "create_hybridqnn_and_fit_and_store_result_(save_path, \"CombinedQnn\", dataset, n, epochs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import qiskit\n",
    "# qiskit.__qiskit_version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48397f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e292864228633949b111a2e6ec7d49bf5d8864587d71a54fa9aff85f9b593d63"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
